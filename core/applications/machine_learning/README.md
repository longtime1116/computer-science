- [x] week1(2018-12-04〜2018-12-10)
  - 教師あり学習(Supervised Learning)
    - 正解を与えて予測させる
    - 回帰(Regression): 連続的な数値を予想する(株価とか)
    - 分類(Classification): 離散的な数字に分類する(true/falseなど)
  - 教師なし学習(Unsupervised Learning)
    - 正解を与えずにクラスタリングする
    - 大量のニュース記事を同じ内容のニュースごとに分けるなど
  - 線形回帰(教師あり学習のモデルのひとつ)
    - Traning Set から Learning Algorithm により関数 h (hypothesis の h) を生み出す。
    - この関数は例えば家のサイズを input としてその販売価格を output とするもの
    - h が直線の時(線形関数に当てはめる時)、それを線形回帰と呼ぶ
  - 目的関数(Cost Function)
    - 線形回帰のモデルの正確さは、目的関数(例えば二乗誤差目的関数)で測ることができる。
    - 目的関数の output が最小になるときのものが、よい仮設関数である。
    - 二乗誤差を使うのは、基本的にそれが一番よくフィットすることが多いから、という理由のようだ
    - 等高線図(Contour plot)という概念
  - 最急降下法(Gradient Descent)
    - 二次元平面の例で直感的に捉えると、勾配の最も急な方向に対して一歩ずつ進んでいき高さが極小になるところまで進んだら満足する、というようなアルゴリズム。
    - θ0 とθ1 は同時に更新していく(同時更新)
- [] week2
- [] week3
- [] week4
- [] week5
- [] week6
- [] week7
- [] week8
- [] week9
- [] week10
- [] week11
